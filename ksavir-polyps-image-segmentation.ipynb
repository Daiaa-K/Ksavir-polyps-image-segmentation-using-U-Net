{"cells":[{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:44:36.903422Z","iopub.status.busy":"2024-10-16T04:44:36.903010Z","iopub.status.idle":"2024-10-16T04:44:36.912542Z","shell.execute_reply":"2024-10-16T04:44:36.911065Z","shell.execute_reply.started":"2024-10-16T04:44:36.903384Z"}},"source":["## About the data:\n","polyps are precursors to colorectal cancer, and is found in nearly half of the individuals at age 50 having a screening colonoscopy, and are increasing with age. Colonoscopy is the gold standard for detection and assessment of these polyps with subsequent biopsy and removal of the polyps. Early disease detection has a huge impact on survival from colorectal cancer, and polyp detection is therefore important. In addition, several studies have shown that polyps are often overlooked during colonoscopies, with polyp miss rates of 14%-30% depending on the type and size of the polyps. Increasing the detection of polyps has been shown to decrease risk of colorectal cancer. Thus, automatic detection of more polyps at an early stage can play a crucial role in improving both prevention of and survival from colorectal cancer. This is the main motivation behind the development of a Kvasir-SEG dataset.\n","\n","The Kvasir-SEG dataset contains 1000 polyp images and their corresponding ground truth from the Kvasir Dataset v2. The resolution of the images contained in Kvasir-SEG varies from 332x487 to 1920x1072 pixels."]},{"cell_type":"markdown","metadata":{},"source":["# Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:16:11.319651Z","iopub.status.busy":"2024-10-16T04:16:11.318898Z","iopub.status.idle":"2024-10-16T04:16:11.348080Z","shell.execute_reply":"2024-10-16T04:16:11.347281Z","shell.execute_reply.started":"2024-10-16T04:16:11.319612Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","import cv2\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import random\n","import numpy as np\n","import pandas as pd\n","import os\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l2\n","import plotly.express as px\n","import plotly.io as pio\n","from plotly.offline import iplot\n","from sklearn.metrics import confusion_matrix, classification_report,roc_curve, auc\n","\n","pio.templates[\"plotly_dark\"].layout.colorway = px.colors.qualitative.Set2\n","pio.templates.default = \"plotly_dark\" "]},{"cell_type":"markdown","metadata":{},"source":["# Loading images and masks"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:16:11.350027Z","iopub.status.busy":"2024-10-16T04:16:11.349722Z","iopub.status.idle":"2024-10-16T04:16:11.372117Z","shell.execute_reply":"2024-10-16T04:16:11.371231Z","shell.execute_reply.started":"2024-10-16T04:16:11.349996Z"},"trusted":true},"outputs":[],"source":["images_dir = r\"kvasir-seg/Kvasir-SEG/images\"\n","masks_dir = r\"kvasir-seg/Kvasir-SEG/masks\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:16:11.373719Z","iopub.status.busy":"2024-10-16T04:16:11.373366Z","iopub.status.idle":"2024-10-16T04:16:11.382163Z","shell.execute_reply":"2024-10-16T04:16:11.381347Z","shell.execute_reply.started":"2024-10-16T04:16:11.373687Z"},"trusted":true},"outputs":[],"source":["def load_image_and_mask(image_path,mask_path):\n","    image_size = (256,256)\n","    img = cv2.imread(image_path)\n","    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","    img = cv2.resize(img,image_size)\n","    \n","    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","    mask = cv2.resize(mask,image_size)\n","    mask = np.expand_dims(mask,axis=-1)\n","    mask = np.where(mask>0,1,0).astype(np.float32)\n","    \n","    return img,mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:16:11.384028Z","iopub.status.busy":"2024-10-16T04:16:11.383754Z","iopub.status.idle":"2024-10-16T04:16:11.392369Z","shell.execute_reply":"2024-10-16T04:16:11.391649Z","shell.execute_reply.started":"2024-10-16T04:16:11.383997Z"},"trusted":true},"outputs":[],"source":["def load_dataset(image_paths,mask_paths):\n","    imgs = []\n","    masks = []\n","    for i,m in zip(image_paths,mask_paths):\n","        img,mask  = load_image_and_mask(i,m)\n","        imgs.append(img)\n","        masks.append(mask)\n","    \n","    return np.array(imgs),np.array(masks)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:16:11.566333Z","iopub.status.busy":"2024-10-16T04:16:11.565937Z","iopub.status.idle":"2024-10-16T04:16:11.935768Z","shell.execute_reply":"2024-10-16T04:16:11.934775Z","shell.execute_reply.started":"2024-10-16T04:16:11.566273Z"},"trusted":true},"outputs":[],"source":["img_p = r\"kvasir-seg/Kvasir-SEG/images/cju0roawvklrq0799vmjorwfv.jpg\"\n","msk_p = r\"kvasir-seg/Kvasir-SEG/masks/cju0roawvklrq0799vmjorwfv.jpg\"\n","img = cv2.imread(img_p)\n","msk = cv2.imread(msk_p,cv2.IMREAD_GRAYSCALE)\n","plt.figure(figsize= (12,15))\n","plt.subplot(1,3,1)\n","plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n","plt.axis('off')\n","\n","plt.subplot(1,3,2)\n","plt.imshow(cv2.cvtColor(msk, cv2.COLOR_BGR2RGB))\n","plt.axis(\"off\")\n","\n","plt.subplot(1,3,3)\n","plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n","plt.imshow(cv2.cvtColor(msk, cv2.COLOR_BGR2RGB),alpha = 0.5)\n","plt.axis(\"off\")\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:16:11.938101Z","iopub.status.busy":"2024-10-16T04:16:11.937791Z","iopub.status.idle":"2024-10-16T04:16:11.949534Z","shell.execute_reply":"2024-10-16T04:16:11.948614Z","shell.execute_reply.started":"2024-10-16T04:16:11.938068Z"},"trusted":true},"outputs":[],"source":["images_paths = [os.path.join(images_dir,f) for f in os.listdir(images_dir)]\n","masks_paths = [os.path.join(masks_dir,f) for f in os.listdir(masks_dir)]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:16:11.951085Z","iopub.status.busy":"2024-10-16T04:16:11.950716Z","iopub.status.idle":"2024-10-16T04:16:11.957481Z","shell.execute_reply":"2024-10-16T04:16:11.956468Z","shell.execute_reply.started":"2024-10-16T04:16:11.951050Z"},"trusted":true},"outputs":[],"source":["len(images_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:16:11.959562Z","iopub.status.busy":"2024-10-16T04:16:11.958894Z","iopub.status.idle":"2024-10-16T04:16:11.966137Z","shell.execute_reply":"2024-10-16T04:16:11.965272Z","shell.execute_reply.started":"2024-10-16T04:16:11.959527Z"},"trusted":true},"outputs":[],"source":["len(masks_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:16:11.969883Z","iopub.status.busy":"2024-10-16T04:16:11.969523Z","iopub.status.idle":"2024-10-16T04:16:22.233395Z","shell.execute_reply":"2024-10-16T04:16:22.232368Z","shell.execute_reply.started":"2024-10-16T04:16:11.969851Z"},"trusted":true},"outputs":[],"source":["images,masks = load_dataset(images_paths,masks_paths)"]},{"cell_type":"markdown","metadata":{},"source":["# Creating U-Net model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:25:18.049826Z","iopub.status.busy":"2024-10-16T04:25:18.049184Z","iopub.status.idle":"2024-10-16T04:25:18.075963Z","shell.execute_reply":"2024-10-16T04:25:18.075084Z","shell.execute_reply.started":"2024-10-16T04:25:18.049785Z"},"trusted":true},"outputs":[],"source":["def u_net():\n","    inputs = layers.Input(shape = (256,256,3))\n","    inputs = layers.Rescaling(scale= 1./255)(inputs)\n","    \n","    #Encoder\n","    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(inputs)\n","    c1 = layers.BatchNormalization()(c1)\n","    c1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(c1)\n","    p1 = layers.MaxPooling2D((2, 2))(c1)\n","\n","    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(p1)\n","    c2 = layers.BatchNormalization()(c2)\n","    c2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(c2)\n","    p2 = layers.MaxPooling2D((2, 2))(c2)\n","\n","    c3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(p2)\n","    c3 = layers.BatchNormalization()(c3)\n","    c3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(c3)\n","    p3 = layers.MaxPooling2D((2, 2))(c3)\n","\n","    c4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(p3)\n","    c4 = layers.BatchNormalization()(c4)\n","    c4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(c4)\n","    p4 = layers.MaxPooling2D((2, 2))(c4)\n","\n","    c5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(p4)\n","    c5 = layers.BatchNormalization()(c5)\n","    c5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(c5)\n","    p5 = layers.MaxPooling2D((2, 2))(c5)\n","    \n","    c6 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(p5)\n","    c6 = layers.BatchNormalization()(c6)\n","    c6 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(c6)\n","\n","\n","    # Decoder\n","    u7 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c6)\n","    u7 = layers.concatenate([u7, c5])\n","    c7 = layers.Conv2D(512, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(u7)\n","    c7 = layers.BatchNormalization()(c7)\n","    c7 = layers.Conv2D(512, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(c7)\n","\n","    \n","    u8 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c7)\n","    u8 = layers.concatenate([u8, c4])\n","    c8 = layers.Conv2D(256, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(u8)\n","    c8 = layers.BatchNormalization()(c8)\n","    c8 = layers.Conv2D(256, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(c8)\n","\n","\n","    u9 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same',kernel_initializer = \"he_normal\")(c8)\n","    u9 = layers.concatenate([u9, c3])\n","    c9 = layers.Conv2D(128, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(u9)\n","    c9 = layers.BatchNormalization()(c9)\n","    c9 = layers.Conv2D(128, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(c9)\n","\n","\n","    u10 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same',kernel_initializer = \"he_normal\")(c9)\n","    u10 = layers.concatenate([u10, c2])\n","    c10 = layers.Conv2D(64, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(u10)\n","    c10 = layers.BatchNormalization()(c10)\n","    c10 = layers.Conv2D(64, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(c10)\n","\n","    \n","    u11 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c10)\n","    u11 = layers.concatenate([u11, c1])\n","    c11 = layers.Conv2D(32, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(u11)\n","    c11 = layers.BatchNormalization()(c11)\n","    c11 = layers.Conv2D(16, (3, 3), activation='relu', padding='same',kernel_initializer = \"he_normal\")(c11)\n","\n","    \n","    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c11)\n","    \n","    model = models.Model(inputs=[inputs],outputs = [outputs])\n","    model.compile(optimizer = 'adam', loss = \"binary_crossentropy\",metrics = [\"accuracy\",tf.metrics.BinaryIoU(target_class_ids=(0, 1))])\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:25:23.210449Z","iopub.status.busy":"2024-10-16T04:25:23.210059Z","iopub.status.idle":"2024-10-16T04:25:23.500268Z","shell.execute_reply":"2024-10-16T04:25:23.499520Z","shell.execute_reply.started":"2024-10-16T04:25:23.210412Z"},"trusted":true},"outputs":[],"source":["model = u_net()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:25:25.044233Z","iopub.status.busy":"2024-10-16T04:25:25.043854Z","iopub.status.idle":"2024-10-16T04:25:25.123354Z","shell.execute_reply":"2024-10-16T04:25:25.122455Z","shell.execute_reply.started":"2024-10-16T04:25:25.044195Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["# Training Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:16:22.643049Z","iopub.status.busy":"2024-10-16T04:16:22.642649Z","iopub.status.idle":"2024-10-16T04:16:22.648533Z","shell.execute_reply":"2024-10-16T04:16:22.647694Z","shell.execute_reply.started":"2024-10-16T04:16:22.643005Z"},"trusted":true},"outputs":[],"source":["check_point = ModelCheckpoint('U-Net.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n","reduce_lr = ReduceLROnPlateau(\n","    monitor='val_loss',  \n","    factor=0.7,          \n","    patience=5,          \n","    min_lr=1e-7,        \n","    verbose=1       \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:25:27.789748Z","iopub.status.busy":"2024-10-16T04:25:27.788869Z","iopub.status.idle":"2024-10-16T04:33:48.922275Z","shell.execute_reply":"2024-10-16T04:33:48.921436Z","shell.execute_reply.started":"2024-10-16T04:25:27.789706Z"},"trusted":true},"outputs":[],"source":["history = model.fit(x=images,y=masks, epochs=50, validation_split = 0.1, batch_size = 16 ,callbacks = [check_point,reduce_lr])"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluating model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:39:48.483578Z","iopub.status.busy":"2024-10-16T04:39:48.483179Z","iopub.status.idle":"2024-10-16T04:39:48.489831Z","shell.execute_reply":"2024-10-16T04:39:48.488991Z","shell.execute_reply.started":"2024-10-16T04:39:48.483540Z"},"trusted":true},"outputs":[],"source":["vals = pd.DataFrame(history.history)\n","vals = vals.rename(columns={\"loss\":\"Train Loss\",\"val_loss\":\"Validation Loss\",\\\n","                            \"accuracy\":\"Train Accuracy\",\"val_accuracy\":\"Validation Accuracy\",\n","                             \"binary_io_u\":\"Train IoU\",\"val_binary_io_u\":\"Validation IoU\"\n","                           })"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:39:50.700597Z","iopub.status.busy":"2024-10-16T04:39:50.700190Z","iopub.status.idle":"2024-10-16T04:39:50.726703Z","shell.execute_reply":"2024-10-16T04:39:50.725722Z","shell.execute_reply.started":"2024-10-16T04:39:50.700559Z"},"trusted":true},"outputs":[],"source":["vals"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:41:15.785537Z","iopub.status.busy":"2024-10-16T04:41:15.785125Z","iopub.status.idle":"2024-10-16T04:41:15.883168Z","shell.execute_reply":"2024-10-16T04:41:15.882172Z","shell.execute_reply.started":"2024-10-16T04:41:15.785497Z"},"trusted":true},"outputs":[],"source":["iplot(px.line(\n","    data_frame = vals,\n","    y = [\"Train Accuracy\",\"Validation Accuracy\"],\n","    labels = {\"index\":\"epochs\",\"value\":\"accuracy\"},\n","    title = \"Accuracy\"\n","))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:41:19.345174Z","iopub.status.busy":"2024-10-16T04:41:19.344782Z","iopub.status.idle":"2024-10-16T04:41:19.436529Z","shell.execute_reply":"2024-10-16T04:41:19.435567Z","shell.execute_reply.started":"2024-10-16T04:41:19.345135Z"},"trusted":true},"outputs":[],"source":["iplot(px.line(\n","    data_frame = vals,\n","    y = [\"Train Loss\",\"Validation Loss\"],\n","    labels = {\"index\":\"epochs\",\"value\":\"Loss\"},\n","    title = \"Loss\"\n","))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:41:23.845186Z","iopub.status.busy":"2024-10-16T04:41:23.844808Z","iopub.status.idle":"2024-10-16T04:41:23.939253Z","shell.execute_reply":"2024-10-16T04:41:23.938381Z","shell.execute_reply.started":"2024-10-16T04:41:23.845149Z"},"trusted":true},"outputs":[],"source":["iplot(px.line(\n","    data_frame = vals,\n","    y = [\"Train IoU\",\"Validation IoU\"],\n","    labels = {\"index\":\"epochs\",\"value\":\"IoU\"},\n","    title = \"IoU(Intersection over Union)\"\n","))"]},{"cell_type":"markdown","metadata":{},"source":["# Predicting an image from segmentation dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:41:30.819328Z","iopub.status.busy":"2024-10-16T04:41:30.818270Z","iopub.status.idle":"2024-10-16T04:41:33.523327Z","shell.execute_reply":"2024-10-16T04:41:33.522371Z","shell.execute_reply.started":"2024-10-16T04:41:30.819258Z"},"trusted":true},"outputs":[],"source":["img = cv2.imread(r\"kvasir-seg/Kvasir-SEG/images/cju0u2g7pmnux0801vkk47ivj.jpg\")\n","img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","img = cv2.resize(img,(256,256))\n","img = np.array(img)\n","msk = cv2.imread(\"kvasir-seg/Kvasir-SEG/masks/cju0u2g7pmnux0801vkk47ivj.jpg\",\\\n","                 cv2.IMREAD_GRAYSCALE)\n","msk = cv2.resize(msk,(256,256))\n","predictions = model.predict(np.expand_dims(img, axis=0), verbose=0)\n","predictions = tf.where(predictions > 0.5, 1.0, 0.0)\n","\n","\n","plt.figure(figsize=(22, 15))\n","plt.subplot(2, 3, 1)\n","plt.title(\"original image\")\n","plt.imshow(img)\n","plt.axis(\"off\")\n","\n","plt.subplot(2, 3, 2)\n","plt.title(\"original mask\")\n","plt.imshow(msk)\n","plt.axis(\"off\")\n","\n","plt.subplot(2, 3, 3)\n","plt.title(\"original image with original mask\")\n","plt.imshow(img)\n","plt.imshow(np.squeeze(msk),alpha=0.5)\n","plt.axis(\"off\")\n","\n","plt.subplot(2,3,4)\n","plt.title(\"original image\")\n","plt.imshow(img)\n","plt.axis(\"off\")\n","\n","plt.subplot(2,3,5)\n","plt.title(\"predicted mask\")\n","plt.imshow(np.squeeze(predictions))\n","plt.axis(\"off\")\n","\n","plt.subplot(2, 3, 6)\n","plt.title(\"original image with predicted mask\")\n","plt.imshow(img)\n","plt.imshow(np.squeeze(predictions),alpha=0.5)\n","plt.axis(\"off\")"]},{"cell_type":"markdown","metadata":{},"source":["# Predicting an image from the classification dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T04:41:47.002437Z","iopub.status.busy":"2024-10-16T04:41:47.001767Z","iopub.status.idle":"2024-10-16T04:41:47.818464Z","shell.execute_reply":"2024-10-16T04:41:47.817589Z","shell.execute_reply.started":"2024-10-16T04:41:47.002393Z"},"trusted":true},"outputs":[],"source":["img = cv2.imread(r\"test img.jpg\")\n","img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","img = cv2.resize(img,(256,256))\n","predictions = model.predict(np.expand_dims(img, axis=0), verbose=0)\n","predictions = tf.where(predictions > 0.5, 1.0, 0.0)\n","\n","\n","plt.figure(figsize=(22, 15))\n","plt.subplot(1, 3, 1)\n","plt.title(\"original image\")\n","plt.imshow(img)\n","plt.axis(\"off\")\n","\n","plt.subplot(1, 3, 2)\n","plt.title(\"predicted  mask\")\n","plt.imshow(np.squeeze(predictions))\n","plt.axis(\"off\")\n","\n","plt.subplot(1, 3, 3)\n","plt.title(\"original image with predicted mask\")\n","plt.imshow(img)\n","plt.imshow(np.squeeze(predictions),alpha=0.5)\n","plt.axis(\"off\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2723494,"sourceId":4708268,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
